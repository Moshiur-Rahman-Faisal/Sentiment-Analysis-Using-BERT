{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-6hmel6sKNSP"
   },
   "outputs": [],
   "source": [
    "def reproduceResult():\n",
    "  seed_value= 0\n",
    "\n",
    "  \n",
    "  with tf.device(\"/cpu:0\"):\n",
    "    ...\n",
    "\n",
    "\n",
    "  os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "  np.random.seed(0)\n",
    "  rn.seed(0)\n",
    "\n",
    "\n",
    "  session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, \n",
    "                                          inter_op_parallelism_threads=1)\n",
    "\n",
    "\n",
    "  tf.compat.v1.set_random_seed(seed_value)\n",
    "  sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "  tf.compat.v1.keras.backend.set_session(sess)\n",
    "  tf.compat.v1.keras.backend.clear_session()\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vURLkAC5_Jp0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\moshi\\AppData\\Local\\Temp/ipykernel_2736/4179402048.py:20: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moshi\\AppData\\Local\\Temp/ipykernel_2736/628588012.py:43: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "  \n",
    "import os \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "from tensorflow import keras\n",
    "\n",
    "reproduceResult()\n",
    "# %tensorflow_version 2.x\n",
    "# import tensorflow as tf\n",
    "# tf.test.gpu_device_name()\n",
    "# from scipy import integrate\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from tensorflow import keras\n",
    "import tempfile\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "# import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "from keras_lr_finder import LRFinder\n",
    "from clr.clr_callback import CyclicLR\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "\n",
    "\n",
    "import keras_tuner\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from attention import Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enjoyment    1965\n",
      "Disgust      1338\n",
      "Other        1291\n",
      "Sadness      1149\n",
      "Anger         480\n",
      "Fear          395\n",
      "Surprise      309\n",
      "Name: Emotion, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188</td>\n",
       "      <td>Other</td>\n",
       "      <td>cho mình xin bài nhạc tên là gì với ạ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>cho đáng đời con quỷ . về nhà lôi con nhà mày ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1345</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>lo học đi . yêu đương lol gì hay lại thích học...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>Enjoyment</td>\n",
       "      <td>uớc gì sau này về già vẫn có thể như cụ này :))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1225</td>\n",
       "      <td>Enjoyment</td>\n",
       "      <td>mỗi lần có video của con là cứ coi đi coi lại ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1220</td>\n",
       "      <td>Anger</td>\n",
       "      <td>thằng kia sao mày bắt vợ với bồ tao dọn thế ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44</td>\n",
       "      <td>Other</td>\n",
       "      <td>một lí do trog muôn vàn lí do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1951</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>thật hay đùa ác vậy . không thể tin được</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1249</td>\n",
       "      <td>Anger</td>\n",
       "      <td>ko phải con mình , mà xem còn thấy đau như vậy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1063</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>per nghe đi rồi khóc 1 trận cho thoải mái . đừ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    Emotion                                           Sentence\n",
       "0         188      Other              cho mình xin bài nhạc tên là gì với ạ\n",
       "1         166    Disgust  cho đáng đời con quỷ . về nhà lôi con nhà mày ...\n",
       "2        1345    Disgust  lo học đi . yêu đương lol gì hay lại thích học...\n",
       "3         316  Enjoyment    uớc gì sau này về già vẫn có thể như cụ này :))\n",
       "4        1225  Enjoyment  mỗi lần có video của con là cứ coi đi coi lại ...\n",
       "5        1220      Anger  thằng kia sao mày bắt vợ với bồ tao dọn thế ki...\n",
       "6          44      Other                      một lí do trog muôn vàn lí do\n",
       "7        1951   Surprise           thật hay đùa ác vậy . không thể tin được\n",
       "8        1249      Anger  ko phải con mình , mà xem còn thấy đau như vậy...\n",
       "9        1063    Sadness  per nghe đi rồi khóc 1 trận cho thoải mái . đừ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_excel('train_nor_811.xlsx') \n",
    "data_test = pd.read_excel('test_nor_811.xlsx')\n",
    "data_val= pd.read_excel('valid_nor_811.xlsx')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = data_train.append(data_test, ignore_index=True)\n",
    "temp= data.append(data_val, ignore_index=True)\n",
    "\n",
    "\n",
    "print(temp.Emotion.value_counts())\n",
    "\n",
    "temp.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DFgD7Seo_Xlq",
    "outputId": "9be2fe5a-b7b5-4488-9cd4-8a48ce6123e8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 4430\n",
      "[[   0    0    0 ...  119   38   22]\n",
      " [   0    0    0 ...  405 2759  308]\n",
      " [   0    0    0 ...  203   20   17]\n",
      " ...\n",
      " [   0    0    0 ...  350 2023 4430]\n",
      " [ 151  100   54 ...   26   18   34]\n",
      " [   0    0    0 ...  100  836   67]]\n",
      "(4431, 300)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(temp, test_size=0.2, stratify = temp['Emotion'], random_state = 42)\n",
    "num_classes = 7\n",
    "embed_num_dims = 300\n",
    "max_seq_len = 50\n",
    "\n",
    "x_train = train['Sentence']\n",
    "x_test = test['Sentence']\n",
    "\n",
    "y_train = train['Emotion']\n",
    "y_test = test['Emotion']\n",
    "\n",
    "texts_train = x_train\n",
    "texts_test = x_test\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train['Sentence'])\n",
    "\n",
    "sequence_train = tokenizer.texts_to_sequences(texts_train)\n",
    "sequence_test = tokenizer.texts_to_sequences(texts_test)\n",
    "\n",
    "index_of_words = tokenizer.word_index\n",
    "\n",
    "vocab_size = len(index_of_words) + 1\n",
    "\n",
    "print('Number of unique words: {}'.format(len(index_of_words)))\n",
    "\n",
    "X_train_pad = pad_sequences(sequence_train, maxlen = max_seq_len, padding='pre' )\n",
    "X_test_pad = pad_sequences(sequence_test, maxlen = max_seq_len,  padding='pre')\n",
    "\n",
    "print(X_train_pad)\n",
    "\n",
    "\n",
    "encoding = {\n",
    "    'Enjoyment': 0,\n",
    "    'Disgust': 1,\n",
    "    'Other': 2,\n",
    "    'Sadness': 3,\n",
    "    'Anger': 4,\n",
    "    'Fear':5,\n",
    "    'Surprise':6\n",
    "}\n",
    "\n",
    "y_train = [encoding[x] for x in train['Emotion']]\n",
    "y_test = [encoding[x] for x in test['Emotion']]\n",
    "\n",
    "\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "def create_embedding_matrix(word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    with open('cc.vi.300.vec',encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word] \n",
    "                embedding_matrix[idx] = np.array(\n",
    "                    vector, dtype=np.float32)[:embedding_dim]\n",
    "    return embedding_matrix\n",
    "\n",
    "\n",
    "embedd_matrix = create_embedding_matrix(index_of_words, embed_num_dims)\n",
    "print(embedd_matrix.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGgsd5mMZPKn"
   },
   "source": [
    "# Random Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3IvOZoK8YGDI",
    "outputId": "fe861031-a89e-45d3-8f7a-42f1e7b6b256",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 05m 44s]\n",
      "val_accuracy: 0.51875901222229\n",
      "\n",
      "Best val_accuracy So Far: 0.5418470501899719\n",
      "Total elapsed time: 05h 18m 00s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in 1646769255\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "attention_unit: 80\n",
      "cnn_1_unit: 80\n",
      "cnn_1_dropout: 0.2\n",
      "lstm_unit: 192\n",
      "lstm_dropout: 0.1\n",
      "cnn_2_unit: 64\n",
      "cnn_2_dropout: 0.2\n",
      "Score: 0.5418470501899719\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "attention_unit: 48\n",
      "cnn_1_unit: 32\n",
      "cnn_1_dropout: 0.2\n",
      "lstm_unit: 96\n",
      "lstm_dropout: 0.30000000000000004\n",
      "cnn_2_unit: 224\n",
      "cnn_2_dropout: 0.1\n",
      "Score: 0.5295815467834473\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "attention_unit: 96\n",
      "cnn_1_unit: 64\n",
      "cnn_1_dropout: 0.30000000000000004\n",
      "lstm_unit: 160\n",
      "lstm_dropout: 0.4\n",
      "cnn_2_unit: 96\n",
      "cnn_2_dropout: 0.30000000000000004\n",
      "Score: 0.5281385183334351\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "attention_unit: 80\n",
      "cnn_1_unit: 64\n",
      "cnn_1_dropout: 0.2\n",
      "lstm_unit: 96\n",
      "lstm_dropout: 0.2\n",
      "cnn_2_unit: 64\n",
      "cnn_2_dropout: 0.1\n",
      "Score: 0.527417004108429\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "attention_unit: 48\n",
      "cnn_1_unit: 48\n",
      "cnn_1_dropout: 0.2\n",
      "lstm_unit: 160\n",
      "lstm_dropout: 0.1\n",
      "cnn_2_unit: 224\n",
      "cnn_2_dropout: 0.5\n",
      "Score: 0.5252525210380554\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "attention_unit: 96\n",
      "cnn_1_unit: 48\n",
      "cnn_1_dropout: 0.2\n",
      "lstm_unit: 128\n",
      "lstm_dropout: 0.30000000000000004\n",
      "cnn_2_unit: 160\n",
      "cnn_2_dropout: 0.2\n",
      "Score: 0.523809552192688\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "attention_unit: 80\n",
      "cnn_1_unit: 80\n",
      "cnn_1_dropout: 0.2\n",
      "lstm_unit: 128\n",
      "lstm_dropout: 0.2\n",
      "cnn_2_unit: 192\n",
      "cnn_2_dropout: 0.2\n",
      "Score: 0.5230880379676819\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "attention_unit: 112\n",
      "cnn_1_unit: 32\n",
      "cnn_1_dropout: 0.2\n",
      "lstm_unit: 192\n",
      "lstm_dropout: 0.4\n",
      "cnn_2_unit: 192\n",
      "cnn_2_dropout: 0.5\n",
      "Score: 0.5209234952926636\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "attention_unit: 48\n",
      "cnn_1_unit: 32\n",
      "cnn_1_dropout: 0.2\n",
      "lstm_unit: 224\n",
      "lstm_dropout: 0.2\n",
      "cnn_2_unit: 96\n",
      "cnn_2_dropout: 0.30000000000000004\n",
      "Score: 0.5202020406723022\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "attention_unit: 112\n",
      "cnn_1_unit: 48\n",
      "cnn_1_dropout: 0.1\n",
      "lstm_unit: 128\n",
      "lstm_dropout: 0.2\n",
      "cnn_2_unit: 256\n",
      "cnn_2_dropout: 0.2\n",
      "Score: 0.51875901222229\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "import time\n",
    "LOG_DIR = f\"{int(time.time())}\"\n",
    "seed_value= 0\n",
    "\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "  \n",
    "  reproduceResult()\n",
    "\n",
    "  print('Ya it comes here')\n",
    "  unit_attention = hp.Int(\"attention_unit\",min_value =32, max_value = 128, step = 16)\n",
    "  fake_val = hp.Int(\"cnn_1_unit\",min_value =16, max_value = 96, step = 16)\n",
    "  cnn_1_unit = hp.Int(\"cnn_1_unit\",min_value =16, max_value = 96, step = 16)\n",
    "  cnn_1_dropout = hp.Float(\"cnn_1_dropout\",min_value = 0.1,max_value = 0.3,step = 0.1)\n",
    "\n",
    "  lstm_unit = hp.Int(\"lstm_unit\",min_value =64, max_value = 256, step = 32)\n",
    "  lstm_dropout = hp.Float(\"lstm_dropout\",min_value = 0.1,max_value = 0.5,step = 0.1)\n",
    "  cnn_2_unit = hp.Int(\"cnn_2_unit\",min_value =64, max_value = 256, step = 32)\n",
    "  cnn_2_dropout = hp.Float(\"cnn_2_dropout\",min_value = 0.1,max_value = 0.5,step = 0.1)\n",
    "\n",
    "\n",
    "\n",
    "  seq_input = keras.layers.Input(shape=(max_seq_len,))\n",
    "\n",
    "  embedded = keras.layers.Embedding(vocab_size,\n",
    "                          embed_num_dims,\n",
    "                          input_length = max_seq_len,\n",
    "                          weights = [embedd_matrix])(seq_input)\n",
    "\n",
    "  cnn = keras.layers.Conv1D(cnn_1_unit,3,kernel_regularizer=regularizers.l2(1e-4),\n",
    "                            bias_regularizer=regularizers.l2(1e-2),\n",
    "                            activity_regularizer=regularizers.l2(1e-4))(embedded)\n",
    "  cnn = keras.layers.Activation(activation='relu')(cnn)\n",
    "  cnn = keras.layers.BatchNormalization()(cnn)\n",
    "  cnn = keras.layers.Dropout(cnn_1_dropout,seed=seed_value)(cnn)\n",
    "\n",
    "  attention_vec = keras.layers.TimeDistributed(keras.layers.Dense(unit_attention))(cnn)\n",
    "  attention_vec = keras.layers.Reshape((48,unit_attention))(attention_vec)\n",
    "  attention_vec = keras.layers.Activation('relu', name = 'cnn_attention_vec')(attention_vec)\n",
    "  attention_output = keras.layers.Dot(axes = 1)([cnn, attention_vec])\n",
    "\n",
    "\n",
    "  lstm = keras.layers.Bidirectional(keras.layers.LSTM(lstm_unit, recurrent_regularizer=regularizers.l2(1e-4),\n",
    "                                                      return_sequences=True,kernel_regularizer=regularizers.l2(1e-4),\n",
    "                                                      bias_regularizer=regularizers.l2(1e-2),\n",
    "                                                      activity_regularizer=regularizers.l2(1e-4),input_shape =(48,)))(attention_output)\n",
    "  lstm = keras.layers.Activation(activation='relu')(lstm)\n",
    "  lstm = keras.layers.BatchNormalization()(lstm)\n",
    "  lstm = keras.layers.Dropout(lstm_dropout,seed=seed_value)(lstm)\n",
    "  \n",
    "  \n",
    "\n",
    "  cnn_2 = keras.layers.Conv1D(cnn_2_unit,3,kernel_regularizer=regularizers.l2(1e-4),\n",
    "                            bias_regularizer=regularizers.l2(1e-2),\n",
    "                            activity_regularizer=regularizers.l2(1e-4))(lstm)\n",
    "  cnn_2 = keras.layers.Activation(activation='relu')(cnn_2)\n",
    "  cnn_2 = keras.layers.BatchNormalization()(cnn_2)\n",
    "  cnn_2 = keras.layers.Dropout(cnn_2_dropout,seed=seed_value)(cnn_2)\n",
    "\n",
    "  max_pooling = keras.layers.GlobalMaxPooling1D()(cnn_2)\n",
    "  output = keras.layers.Dense(num_classes, activation='softmax')(max_pooling)\n",
    "\n",
    "  model = keras.Model(inputs = [seq_input], outputs = output)\n",
    "  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "stop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                              patience=4,\n",
    "                              restore_best_weights=True,\n",
    "                              verbose=0, mode='max')\n",
    "\n",
    "\n",
    "clr_step_size = int((len(X_train_pad)/64))\n",
    "base_lr = 1e-3\n",
    "max_lr = 6e-3\n",
    "mode = 'exp_range'\n",
    "\n",
    "\n",
    "clr = CyclicLR(base_lr = base_lr, max_lr = max_lr, step_size = clr_step_size, mode = mode)\n",
    "\n",
    "\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective = keras_tuner.Objective('val_accuracy', direction=\"max\"),\n",
    "    max_trials = 50,\n",
    "    executions_per_trial = 1,\n",
    "    directory = LOG_DIR\n",
    "    )\n",
    "  \n",
    "tuner.search(x=X_train_pad,y = y_train,epochs = 20, batch_size = 128,callbacks = [stop,clr], \n",
    "             validation_data = (X_test_pad,y_test))\n",
    "\n",
    "\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "100_percent_test_BiLSTM_best_model_git.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
